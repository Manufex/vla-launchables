services:
  lerobot:
    build:
      context: .
      dockerfile: Dockerfile.groot

    network_mode: "host"
    runtime: nvidia

    environment:
      ENV: ${ENV:-brev}

      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility

      HF_HUB_ENABLE_HF_TRANSFER: "1"
      TOKENIZERS_PARALLELISM: "false"

      # W&B (WANDB_API_KEY is passed at runtime by run.sh)
      WANDB_PROJECT: ${WANDB_PROJECT:-vla-train-lab}
      WANDB_SILENT: "true"

    volumes:
      - .:/workspace
      - ../outputs:/workspace/outputs
      - ../cache:/workspace/cache

      # Cache volumes (shared across all models)
      - hf-cache:/root/.cache/huggingface
      - torch-cache:/root/.cache/torch
      - pip-cache:/root/.cache/pip
      - wandb-cache:/root/.local/share/wandb

    working_dir: /workspace
    shm_size: "16gb"
    stdin_open: true
    tty: true

volumes:
  hf-cache:
  torch-cache:
  pip-cache:
  wandb-cache:

